### Understanding the Data

```py
import pandas as pd
```
```py
advertising = pd.read_csv('/content/tvmarketing.csv')

# Column TV - advertising budget spent on TV marketing 
# Column Sales - the actual sales (how much we have sold/sales)
```
```py
advertising.head() # first 5 rows
```
```py
advertising.describe()
```
```py
# Visualising the Dataset

import seaborn as sns
```
```py
sns.regplot(data=advertising, x='TV',y="Sales",ci=99,marker="x",color="black",line_kws=dict(color="green"))
```
```py
# Pearson correlation koeficient

advertising.corr() #calculating correlation for the whole dataframe
```
### Correlation reminder

Weak Correlation: 0 to ±0.3

Moderate Correlation: ±0.3 to ±0.7

Strong Correlation: ±0.7 to ±1


```py
advertising['TV'].corr(advertising['Sales']) # positive, strong correlation
```
### SUPERVISED VS UNSUPERVISED learning

* Supervised learning: You have input data and know the correct answers (labels or targets). The model learns to map inputs to the correct outputs. Think of it like having a teacher who shows you the right answers as you learn.

* Unsupervised learning: You only have input data with no correct answers. The model tries to find patterns or groups in the data on its own. It's like exploring a puzzle without knowing what the final picture looks like.

Supervised learning is like studying with an answer key, while unsupervised learning is like figuring things out without any hints.

Supervised learning models would have a baseline understanding of what the correct output values should be.

### IN SHORT: In unsupervised - you don't have labeled data, in supervised - the data is labeled. 

![Screenshot 2024-08-17 at 10 28 14](https://github.com/user-attachments/assets/b639e483-89f0-4785-9fdb-4d73670d2d7d)

### Scikit library:
Simple and efficient tools for predictive data analysis
Accessible to everybody, and reusable in various contexts
Built on NumPy, SciPy, and matplotlib
Open source, commercially usable - BSD license

https://scikit-learn.org/stable/
https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html

```py
# Preparing X and Y 

X = advertising.drop('Sales', axis=1) # independent variable 

X.head()
```
```py
Y = advertising.drop('TV', axis=1) # the outcome, dependent

Y.head()
```

# Splitting data into Train/Test sets

```py
from sklearn.model_selection import train_test_split
```
```py
X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.7) # usually X is written as capital letter and y as lower case.

# 0.7 specify that 70% of the data should be used for training and 30% for testing.

X_train
```
### Column/ROW
* COLUMN - also called a FEATURE
* ROW - also called an OBSERVATION

## Train the model 

```py
from sklearn.linear_model import LinearRegression # Import the model
```
```py
model = LinearRegression() # Initialize the model
```
```py
model.fit(X_train, y_train) # Fit the model
```

### Y = mX + b

Here's what each part represents:
Y: The dependent variable or the output value you want to predict.
X: The independent variable or the input value you use to make the prediction.
m: The slope of the line, which indicates how much Y changes for a unit change in X
b: The y-intercept, which is the value of Y when X is 0. It represents where the line crosses the Y-axis.

```py
print(f'Model intercept is: {model.intercept_}')
print(f'Model coeficient is: {model.coef_}')
```
```py
my_new_budget = [[50]] # double square brackets create 2D Array Dataset

my_predicted_sales = model.predict(my_new_budget)

print(f'When the new budget is {my_new_budget[0][0]}, then predicted sales are: {round (my_predicted_sales[0][0])}') # the [0][0] gets rid of the double [[]]

X_test.head()
```
```py
y_pred = model.predict(X_test)
```
```py
final_df = pd.DataFrame()
final_df['TV'] = X_test
final_df['Actual_sales'] = y_test
final_df['Predicted_sales'] = y_pred

final_df.head()
```
```py
final_df['ABS_Error_Actual_vs_Predicted'] = abs(final_df['Actual_sales']-final_df['Predicted_sales'])
```
```py
final_df.head()
```



