Lesson 23 Topic: Confusion matrix & Clustering

## Clustering

✨ Utilities to load popular datasets and artificial data generators -> https://scikit-learn.org/dev/api/sklearn.datasets.html

✨ Unsupervised VS Supervised learning

![Screenshot 2024-09-28 at 10 03 24](https://github.com/user-attachments/assets/6fba381a-fc2e-4b98-a761-078eac56782b)


* Dots being in the same color means that input data isn't labeled. In supervised learning - the data is labeled, as we see here from two different colors and grouping.
* When new points come in, the model will not retrain on those points. You need to retrain the model yourself. 

✨ Visualising decision boundaries 

![Screenshot 2024-09-28 at 10 52 17](https://github.com/user-attachments/assets/8a90222d-68b1-403d-b4c3-42de1d13cb91)


https://stackoverflow.com/questions/22294241/plotting-a-decision-boundary-separating-2-classes-using-matplotlibs-pyplot

✨ A practical example of where this would be needed - Spotify, using functionality for listening to random songs or Netflix with movie suggestions etc.

✨ Unsupervised learning example (clustering) -> Using synthetic data here (not real data, but rather something made for learning purposes)

```py
from sklearn.datasets import make_blobs # creating synthetic dataset
```
```py
X, y = make_blobs(n_samples=100000, centers=6, cluster_std=0.80)

# X[:, 0] x coordinate
# X[:, 1] y coordinate
# y is the cluster of the point
```
```py
import matplotlib.pyplot as plt

plt.scatter(X[:, 0], X[:, 1], c='grey', edgecolors='k')
```
```py
from sklearn.cluster import KMeans # importing model
```
```py
kmeans = KMeans(n_clusters=5) # initializing the model
```
```py
kmeans.fit(X) # fitting(training) the model
```
```py
cluster_labels = kmeans.predict(X) # predict
```
```py
plt.scatter(X[:, 0], X[:, 1], c=cluster_labels, edgecolors='k')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, marker='*', c='red')
```
```py
kmeans.cluster_centers_[:, 0] # accessing cluster centers
kmeans.cluster_centers_[:, 1]
```




## Confusion matrix 

A confusion matrix is a table used to describe the performance of a classification model. 
It shows how many predictions your model got right and wrong for each category, comparing the actual labels with the model’s predicted labels.


![Screenshot 2024-09-28 at 11 20 28](https://github.com/user-attachments/assets/fef18579-1cd9-4945-9d36-11afd8c54b7a)



![Screenshot 2024-09-28 at 11 35 10](https://github.com/user-attachments/assets/11e010e0-3545-4f25-9598-62348978b455)



![Screenshot 2024-09-28 at 11 38 56](https://github.com/user-attachments/assets/7c4f1b20-3689-4dcd-941a-30ceb5a0b57f)


### Data extraction

```py
import seaborn as sns
import pandas as pd 

titanic_data = sns.load_dataset('titanic')
```

### Data review

```py
print("Number of passangers:",len(titanic_data))
titanic_data.columns 
titanic_data.dtypes 

titanic_data['class'].unique()

titanic_data.isnull().sum()
```

### Data transformation

```py
titanic_data['deck'] = titanic_data['deck'].astype(str) 
titanic_data['class'] = titanic_data['class'].astype(str)
titanic_data.fillna(0, inplace=True)
titanic_data.drop(['alive', 'alone', 'adult_male', 'deck'], axis=1, inplace=True)

titanic_data.isnull().sum()

titanic_data['embark_town'].unique()
```

```py
# Mapping for embark_town
embark_town_mapping = {'Southampton': 1, 'Cherbourg': 2, 'Queenstown': 3, 0:0}
titanic_data['embark_town'] = titanic_data['embark_town'].map(embark_town_mapping)

# Mapping for sex
sex_mapping = {'male': 0, 'female': 1}
titanic_data['sex'] = titanic_data['sex'].map(sex_mapping)

# Mapping for embarked
embarked_mapping = {'S': 1, 'C': 2, 'Q': 3, 0 : 0}
titanic_data['embarked'] = titanic_data['embarked'].map(embarked_mapping)

# Mapping for class
class_mapping = {'Third': 1, 'First': 2, 'Second': 3}
titanic_data['class'] = titanic_data['class'].map(class_mapping)

# Mapping for who
who_mapping = {'man': 1, 'woman': 2, 'child': 3}
titanic_data['who'] = titanic_data['who'].map(who_mapping)
```

```py
titanic_data.isnull().sum() #NO MORE EMPTY VALUES
```

### Train and Test split

```py
from sklearn.model_selection import train_test_split
```
```py
X = titanic_data.drop('survived', axis=1) #Independent variables
y = titanic_data['survived'] #Dependent variable
```
```py
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 )
```

### Create data model 

```py
from sklearn.neighbors import KNeighborsClassifier # import the model
```
```py
model = KNeighborsClassifier() # initialize
```
```py
model.fit(X_train, y_train) # train(fit) the model
```
```py
prediction_knn = model.predict(X_test) # prediction on test dataset, because test dataset has not seen the model
```

### How good is the model?

```py
from sklearn.metrics import accuracy_score
```
```py
accuracy_score(prediction_knn, y_test)
```

### Confusion Matrix

```py
from sklearn.metrics import confusion_matrix
```
```py
cm = confusion_matrix(y_test, prediction_knn)
```
```py
print(cm)
```
```py
import seaborn as sns
import matplotlib.pyplot as plt
```
```py
# visualizing a heatmap from confusion matrix using seaborn

sns.heatmap(cm, annot = True, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True Labels')
```

![Screenshot 2024-09-28 at 11 55 24](https://github.com/user-attachments/assets/826ec840-5ead-4722-bcbc-bd594247287d)



# TEAMWORK:

1. Look at what is Central Limit Theorem and try to prove/ visualize it using NumPy

   https://www.geeksforgeeks.org/python-central-limit-theorem/

2. Watch the movie The Great Hack (https://www.imdb.com/title/tt4736550/)  
or read about Cambridge Analytica (https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html)


