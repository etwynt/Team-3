üî¢ Project 3: Titanic data
1. Using several classification models
2. Training classification models
3. Comparing classification models (accuracy score)
4. Confusion matrix

### DATA IMPORT

```py
import seaborn as sns
import pandas as pd

titanic_data = sns.load_dataset('titanic')

titanic_data.head()
```

### Data INVESTIGATION

```py
titanic_data.isnull().sum() #checking null values
titanic_data.dtypes
```

```py
titanic_data.drop('deck', axis=1, inplace=True) #dropping column with a lot of empty values
```

### Data Transformation

```py
titanic_data['class'] = titanic_data['class'].astype(str) # modified the object from category to string

titanic_data.fillna(0, inplace=True) # this command replaces empty with null values
```
```py
titanic_data.head()
```
```py
titanic_data['sex'].unique()
```
```py
titanic_data['who'].unique()
```
```py
# sex column

sex_mapping = {'male': 0, 'female': 1}
titanic_data['sex'] = titanic_data['sex'].map(sex_mapping)
```
```py

# Embark town

titanic_data['embark_town'].unique()
embark_town_mapping = {'Southampton': 1, 'Cherbourg': 2, 'Queenstown': 3, 0:0}
titanic_data['embark_town'] = titanic_data['embark_town'].map(embark_town_mapping)
```

```py
# Embarked
titanic_data['embarked'].unique()
embarked_mapping = {'S': 1, 'C': 2, 'Q': 3, 0:0}
titanic_data['embarked'] = titanic_data['embarked'].map(embarked_mapping)
```

```py
# Who
titanic_data['who'].unique()
who_mapping = {'man': 1, 'woman': 2, 'child': 3, 0:0}
titanic_data['who'] = titanic_data['who'].map(who_mapping)
```

```py
titanic_data.info()
```

### Data modeling ###

```py
from sklearn.model_selection import train_test_split

X = titanic_data.drop('survived', axis=1) # Features
y = titanic_data['survived'] # Dependent variable
```
```py
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)
```

### Logistic Regression ###

```py
from sklearn.linear_model import LogisticRegression #import
```
```py
model = LogisticRegression() #initialize
```
```py
model.fit(X_train, y_train) #train
```
```py
prediction_results = model.predict(X_test)
prediction_results
```

## TEAMWORK ##
EASY: add DecisionTreeClassifier to titanic data predictions. 

HARD: Investigate what is cross-validation and implement cross-validation on any classification model you prefer on Titanic data. Explain to each other, what do you see. 

Example: 
```py
k_fold = KFold(n_splits=10, shuffle=True, random_state=42)
accuracy_scores = cross_val_score(model_knn_cv, X, y, cv=k_fold, scoring='accuracy')
```
### DecisionTreeClassifier ###

```py
from sklearn.tree import DecisionTreeClassifier # import
model2 = DecisionTreeClassifier() # initialize
model2.fit(X_train, y_train) # train

prediction_results2 = model2.predict(X_test)
prediction_results2
```

### What is Cross-Validation? ###
**Cross-validation** is a statistical technique used to assess the performance and generalizability of a machine learning model. The basic idea is to divide the data into several subsets, train the model on some of these subsets, and test it on the remaining ones. This process is repeated multiple times to ensure that the model's performance is consistent across different splits of the data.

One of the most commonly used forms of cross-validation is **k-fold cross-validation**:

1. The dataset is split into ùëò equally sized folds (subsets).
2. The model is trained on ùëò ‚àí 1 folds and tested on the remaining one fold. This process is repeated ùëò times, with each fold being used exactly once as the test set.
3. The results from the ùëò iterations are averaged to produce a single estimation of the model‚Äôs performance.
   
This method provides a better estimation of model performance than a simple train-test split, as it reduces the variance associated with how the data is split.

```py
from sklearn.model_selection import KFold, cross_val_score

k_fold = KFold(n_splits=10, shuffle=True, random_state=42)
accuracy_scores = cross_val_score(model2, X, y, cv=k_fold, scoring='accuracy')

mean_accuracy = accuracy_scores.mean()
std_accuracy = accuracy_scores.std()

print(f"Mean Accuracy: {mean_accuracy}")
print(f"Standard Deviation of Accuracy: {std_accuracy}")
print(f"All Accuracy Scores: {accuracy_scores}")
```

![image](https://github.com/user-attachments/assets/796fa4e1-ec62-46ab-b778-967924f09fa7)
